{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrian-Vehicle Proximity Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This demo aims to output the distances between vehicles and pedestrians overlayed on the source footage. To achieve this, the following steps are taken:\n",
    "\n",
    "- Parse input arguments\n",
    "- Locate and read source footage\n",
    "- Detect desired objects\n",
    "- Calculate pixel distances between vehicle class objects and pedestrians\n",
    "- Convert pixel distances to real distances\n",
    "- Save final video to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import Code Dependencies\n",
    "\n",
    "Install necessary packages and import into program as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Image Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Draw Bounding Box Around Detected Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = boxColour(class_id)\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Calculate Distance Between Two Given Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(pt1,pt2):\n",
    "    try:\n",
    "        return ((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)**0.5\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Calculate Midpoint of Two Given Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(pt1,pt2):\n",
    "    try:\n",
    "        return [(pt1[0]+pt2[0])//2, (pt1[1]+pt2[1])//2]\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Determine Line Colour\n",
    "\n",
    "This function determines the colour of the line joining any vehicle to any pedestrian. It is either drawn in red (when distance is below safety trheshold) or green (when distance is above safety threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColour(distance, threshold):\n",
    "    try:\n",
    "        red = (0,0,255)\n",
    "        green = (0,255,0)\n",
    "        if distance < threshold:\n",
    "            return red\n",
    "        else:\n",
    "            return green\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 Determine Bounding Box Colour\n",
    "\n",
    "Using Deloitte colours, bounding boxes have two possible colours to determine class - either vehicle or pedestrian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxColour(class_id):\n",
    "    person = (249,194,99)\n",
    "    vehicle = (80,208,172)\n",
    "    if class_id == 0:\n",
    "        return person\n",
    "    else:\n",
    "        return vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Program Code\n",
    "\n",
    "The program is initiated via command line, taking the following form:\n",
    "\n",
    "```\n",
    "python [filename] --image [file path to video file] --config [file path to yolo config file] --weights [file path to yolo pre-trained weights] --classes [file path to text file containing class names]\n",
    "```\n",
    "\n",
    "By not integrating the model files with the code, the user is allowed the flexibility of refining the model without the need for changing or adjusting code in the demo program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Parse Command Line Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('-i', '--image', required=True,\n",
    "                help = 'path to input image')\n",
    "ap.add_argument('-c', '--config', required=True,\n",
    "                help = 'path to yolo config file')\n",
    "ap.add_argument('-w', '--weights', required=True,\n",
    "                help = 'path to yolo pre-trained weights')\n",
    "ap.add_argument('-cl', '--classes', required=True,\n",
    "                help = 'path to text file containing class names')\n",
    "args = ap.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define Parameters\n",
    "\n",
    "Two main parameters are used in this program. These numbers may require adjustment for each input video.\n",
    "\n",
    "- Safety Threshold\n",
    "    - This is the safety threshold in metres.\n",
    "    - The distances are measured from the centre of the bottom edge of the bounding boxes, and may not reflect the closest separation between objects.\n",
    "    - To account for this, it is recommended that the safety threshold is increased as a buffer.\n",
    "- Real Vehicle Length\n",
    "    - This is the real length of the most common vehicle in any given frame. \n",
    "    - This parameter is used to generate a pixel-to-real ratio and convert pixel distances to real distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 10\n",
    "avg_suv = 4.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Read Video File and Create Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(args.image)\n",
    "_,frame = cap.read()\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "writer = cv2.VideoWriter('PROXIMITY_distance_trial_4.avi', fourcc, 30, (frame.shape[1], frame.shape[0]), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Main Code Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1.1 Run Loop as Long as Video Frames Continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code sits within an ```if``` statement nested within a ```while``` loop. This ensures that the program runs for as long as there are video frames to read.\n",
    "\n",
    "```\n",
    "ret = True\n",
    "while ret:\n",
    "    ret, image = cap.read()\n",
    "    if ret:\n",
    "```\n",
    "\n",
    "Within this, the following code is run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1.2 Object Detection Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract image details and define scale. Then, read Yolo files to obtain network.\n",
    "\n",
    "Generate a blob to be fed into layers.\n",
    "\n",
    "```\n",
    "Width = image.shape[1]\n",
    "Height = image.shape[0]\n",
    "scale = 0.00392\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(args.classes, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "net = cv2.dnn.readNet(args.weights, args.config)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outs = net.forward(get_output_layers(net))\n",
    "```\n",
    "\n",
    "We are only interested in objects belonging to the first 10 classes in the text file, hence the line ```class_id < 9```. This corresponds to human objects and all vehicles we expect to see in our source videos. Alternatively, the classes file can be edited.\n",
    "\n",
    "The bounding boxes for all captured onjects are recorded in ```boxes```.\n",
    "\n",
    "```\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5 and class_id < 9:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1.3 Sort and Display Bounding Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "vehicles = []\n",
    "pedestrians = []\n",
    "true_length_bank = []\n",
    "\n",
    "for i in indices:\n",
    "    try:\n",
    "        box = boxes[i]\n",
    "    except:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "\n",
    "    x = round(box[0])\n",
    "    y = round(box[1])\n",
    "    w = round(box[2])\n",
    "    h = round(box[3])\n",
    "    draw_prediction(image, class_ids[i], confidences[i], x, y, x+w, y+h)\n",
    "\n",
    "    if class_ids[i] == 0:\n",
    "        pedestrians.append(midpoint([x,y+h],[x+w,y+h]))\n",
    "    elif class_ids[i] < 9:\n",
    "        vehicles.append(midpoint([x,y+h],[x+w,y+h]))\n",
    "        true_length_bank.append(avg_suv/dist(midpoint([x,y+h],[x+w,y+h]),[x+w,y]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1.4 Calculate True Length Conversion Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```t_factor``` is the transformation factor, which is the average of all caluculated pixel-to-real ratios within the video frame.\n",
    "```\n",
    "t_factor = np.mean(true_length_bank)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1.5 Calculate Distance Between Vehicle and Pedestrian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by looping through all vehicles and pedestrians in object banks.\n",
    "```\n",
    "for i in range(len(vehicles)):\n",
    "            for j in range(len(pedestrians)):\n",
    "```\n",
    "Convert pixel distances to real distances by multiplying by tranformation factor (pixel-to-real ratio).\n",
    "```\n",
    "                distance = dist(vehicles[i], pedestrians[j]) * t_factor\n",
    "```\n",
    "\n",
    "Filter out long distances as they will not be relevant.\n",
    "This upper boundary may need to be adjusted depending on the nature of the source video.\n",
    "```\n",
    "                if distance <= 2 * thresh:\n",
    "```\n",
    "Locate a point along the line connecting the vehicle and pedestrian to print distance value. Also specify the font, font size, and font colour.\n",
    "Font colour is dependent on whether the distance value breaches the threshold value.\n",
    "```\n",
    "                    org = midpoint(vehicles[i], pedestrians[j])\n",
    "                    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "                    font_size = 1\n",
    "                    colour = getColour(distance, thresh)\n",
    "```\n",
    "Print connecting line and distance value to video frame.\n",
    "```\n",
    "                    cv2.line(image, vehicles[i], pedestrians[j], colour, 2)\n",
    "                    cv2.putText(image, str(round(distance,1)), org, font, font_size, colour)\n",
    "```\n",
    "\n",
    "Write frame to file.\n",
    "```\n",
    "        writer.write(image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Code in Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "while ret:\n",
    "    ret, image = cap.read()\n",
    "    if ret:\n",
    "        Width = image.shape[1]\n",
    "        Height = image.shape[0]\n",
    "        scale = 0.00392\n",
    "\n",
    "        classes = None\n",
    "\n",
    "        with open(args.classes, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        net = cv2.dnn.readNet(args.weights, args.config)\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        outs = net.forward(get_output_layers(net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.5\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5 and class_id < 9:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        # store bounding box coords of objects\n",
    "        vehicles = []\n",
    "        pedestrians = []\n",
    "        true_length_bank = []\n",
    "\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except:\n",
    "                i = i[0]\n",
    "                box = boxes[i]\n",
    "    \n",
    "            x = round(box[0])\n",
    "            y = round(box[1])\n",
    "            w = round(box[2])\n",
    "            h = round(box[3])\n",
    "            draw_prediction(image, class_ids[i], confidences[i], x, y, x+w, y+h)\n",
    "\n",
    "            if class_ids[i] == 0:\n",
    "                pedestrians.append(midpoint([x,y+h],[x+w,y+h]))\n",
    "            elif class_ids[i] < 9:\n",
    "                vehicles.append(midpoint([x,y+h],[x+w,y+h]))\n",
    "                true_length_bank.append(avg_suv/dist(midpoint([x,y+h],[x+w,y+h]),[x+w,y]))\n",
    "\n",
    "        # calculate true length conversion\n",
    "        t_factor = np.mean(true_length_bank)\n",
    "        distances = []\n",
    "\n",
    "        # calculate distance from middle of bottom edge\n",
    "\n",
    "        for i in range(len(vehicles)):\n",
    "            for j in range(len(pedestrians)):\n",
    "                distance = dist(vehicles[i], pedestrians[j]) * t_factor\n",
    "                if distance <= 2 * thresh:\n",
    "                    org = midpoint(vehicles[i], pedestrians[j])\n",
    "                    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "                    font_size = 1\n",
    "                    colour = getColour(distance, thresh)\n",
    "                    cv2.line(image, vehicles[i], pedestrians[j], colour, 2)\n",
    "                    cv2.putText(image, str(round(distance,1)), org, font, font_size, colour)\n",
    "\n",
    "        writer.write(image)\n",
    "        #cv2.imshow(\"object detection\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Ending Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
